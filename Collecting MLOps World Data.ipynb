{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running ETL to Add MLOps World Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: MLOps World Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We draw videos from four playlists, representing MLOps World conferences in 2021 and 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "with open(\"data/mlops-world-playlists.json\", \"r\") as f:\n",
    "    playlists = json.load(f)\n",
    "\n",
    "pp.pprint(playlists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://www.youtube.com/playlist?list={playlists[0]['playlistId']}\"\n",
    "url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan of Attack:\n",
    "1. Collect the IDs for all of the videos by calling the YouTube API with `requests`.\n",
    "2. Grab the subtitles for each video using the `youtube-transcript-api` Python SDK.\n",
    "3. Reorganize the subtitles using `srt`.\n",
    "4. Pass them up to MongoDB (using `pymongo`) for storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that's going to mean adding a bunch of dependencies to our project,\n",
    "and we don't need them anywhere else,\n",
    "like in the chatbot application.\n",
    "\n",
    "Plus, once we start adding more kinds of ETL,\n",
    "like Markdown files or SQL databases,\n",
    "everything gets worse:\n",
    "the chance of conflict goes up, the setup gets harder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a better way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yes, let's use Modal for ETL (and everything else)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modal is a serverless runtime based on snappy, scalable, and Pythonic creation and deployment of containerized applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import etl.videos as videos\n",
    "from etl.shared import display_modal_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Containers are based on images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_modal_image(videos.image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applications are defined not by images but by `Stub`s,\n",
    "which combine images with configuration, like mounted volumes and secrets,\n",
    "and manage application lifecycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos.stub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of depth there, but for now,\n",
    "the important thing is that a `Stub`\n",
    "lets us run certain functions in containers on Modal's infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(videos.stub.registered_functions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modal is a cloud service, so you'll need an account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you don't have an acoount,you can get one by running the command below:\n",
    "```bash\n",
    "!make modal-token\n",
    "``````\n",
    "Follow the instructions, adding the token to your `.env.dev` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can authenticate with the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env ENV=dev\n",
    "!make modal-auth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see it in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, we collect the IDs for the videos we want to add to our chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The YouTube API is a huge pain to use.\n",
    "\n",
    "The official SDK isn't much better, and it requires OAuth.\n",
    "\n",
    "So let's just pull the info we need with `requests`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a function defined in our `videos` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos.get_playlist_videos.get_raw_f()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we'll execute it `remote`ly, inside the container defined by `videos.image`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with videos.stub.run():\n",
    "    mlops_world_videos = videos.get_playlist_videos.remote(playlists[0][\"playlistId\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mlops_world_videos))\n",
    "mlops_world_videos[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we're executing in a container,\n",
    "we can execute in multiple containers concurrently without any extra work.\n",
    "\n",
    "We just `.map` instead of calling `.remote`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with videos.stub.run():\n",
    "    videos_by_playlist = videos.get_playlist_videos.map(pl[\"playlistId\"] for pl in playlists[1:])\n",
    "    [mlops_world_videos.extend(playlist_videos) for playlist_videos in videos_by_playlist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mlops_world_videos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll persist the results to a file so we can use them later if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/mlops-world-videos.json\", \"w\") as f:\n",
    "    json.dump(mlops_world_videos, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/mlops-world-videos.json\", \"r\") as f:\n",
    "    mlops_world_videos = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, let's get the subtitles for each video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the YouTube API is a pain and there just so bappens to be a tightly-specialized Python library\n",
    "for getting subtitles from YouTube videos.\n",
    "\n",
    "Not worth polluting a global environment for, but as an addition to a sub-application specific container, it's perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>Note that we use a new feature of `Modal.Function`s: a `concurrency_limit`.\n",
    "Always be polite when using pirate APIs!</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with videos.stub.run():\n",
    "    transcripts = videos.get_transcript.map([video[\"id\"] for video in mlops_world_videos])\n",
    "    transcripts = [transcript for transcript in transcripts if transcript is not None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts[0][:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we merge these subtitle lines into chapter transcripts.\n",
    "\n",
    "Subtitles on YouTube are optimized for displaying alongside a video,\n",
    "but we want something more like a written transcript.\n",
    "\n",
    "That'll be easier for our language model to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we also want to respect the substructure of videos -- YouTube videos are often broken into chapters,\n",
    "which typically contain discrete topics or content.\n",
    "\n",
    "Preserving this structure will also make it easier to provide contextualized information to the language model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get the chapter information from the YouTube API, so let's do another `map`ped API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with videos.stub.run():\n",
    "    chapters_by_video = list(videos.get_chapters.map([video[\"id\"] for video in mlops_world_videos]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of Chapters: {len(chapters_by_video)}\")\n",
    "print(f\"Number of Videos: {len(mlops_world_videos)}\")\n",
    "# some videos don't have chapters, so we added in a fake chapter for those\n",
    "real_chapters = [chapters for chapters in chapters_by_video if chapters[0]['title'] != 'Full Video']\n",
    "print(f\"Fraction of Videos with Real Chapters: {round(len(real_chapters) / len(mlops_world_videos), 2)}\")\n",
    "real_chapters[:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take the transcript for each chapter\n",
    "and convert into a more generic `Document` format\n",
    "(courtesy of `langchain`).\n",
    "\n",
    "But what's really cool here is that we've now got over ðŸ’¯ documents,\n",
    "and Modal will run the generation process concurrently across all of them --\n",
    "on up to 100 containers at once!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example isn't the most exciting, sure --\n",
    "but imagine we had to transcribe the videos ourselves with a STT model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with videos.stub.run():\n",
    "    chapters_by_video = list(videos.stub.add_transcript.map(chapters_by_video, transcripts))\n",
    "    video_ids, video_titles = zip(*map(lambda dct: dct.values(), mlops_world_videos))  # \"transpose\": list of two-entry dicts -> tuple of lists\n",
    "    documents = list(videos.stub.create_documents.map(chapters_by_video, video_ids, video_titles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[2][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etl.shared import unchunk\n",
    "\n",
    "flat_documents = unchunk(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_documents[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, let's send the data into a structured store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using MongoDB,\n",
    "but for small scale the database you use doesn't matter so much.\n",
    "\n",
    "We might've used Redis or Postgres,\n",
    "or any general database that also has vector indexing,\n",
    "or we might've gone directly to a vector database like\n",
    "Milvus, Weaviate, Vespa, Pinecone, or Chroma.\n",
    "\n",
    "Schemaless-ness is nice for a simple project,\n",
    "and Mongo's JSON documents map neatly onto JSON-y\n",
    "Pydantic models, like those used in LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etl import shared\n",
    "\n",
    "\n",
    "display_modal_image(shared.image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to set up an instance on MongoDB Atlas to proceed.\n",
    "\n",
    "See the instructions under `setup/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make secrets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll drop any existing instances of the collection,\n",
    "then insert our new documents.\n",
    "\n",
    "We use a concurrency limit and bulk writes to control the load on the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, collection = \"fsdl-dev\", \"ask-fsdl\"  # we run this in a dev database\n",
    "\n",
    "# drop the collection if it exists, it's just dev\n",
    "!modal run app.main::drop_docs --db {db} --collection {collection}\n",
    "\n",
    "\n",
    "# add the documents to the database\n",
    "with shared.stub.run():\n",
    "    # split into 10 chunks, matching concurrency limit of adder\n",
    "    chunked_documents = shared.chunk_into(flat_documents, 10)\n",
    "    list(\n",
    "        shared.add_to_document_db.map(\n",
    "            chunked_documents, kwargs={\"db\": db, \"collection\": collection}\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check we did everything right, let's do a quick query to pull out a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with shared.stub.run():\n",
    "    # pull only YouTube videos\n",
    "    query = {\"metadata.source\": {\"$regex\": \"youtube\", \"$options\": \"i\"}}\n",
    "    # project out the text field, it can get large\n",
    "    projection = {\"text\": 0}\n",
    "    # get just one result to show it worked\n",
    "    result = shared.query_one.remote(query, projection, db=db, collection=collection)\n",
    "\n",
    "pp.pprint(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "id_str, time_str = result[\"metadata\"][\"source\"].split(\"?v=\")[-1].split(\"&t=\")\n",
    "YouTubeVideo(id_str, start=int(time_str.strip(\"s\")), width=800, height=400)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okay but for real though, this is ML _Ops_ World: how do we do this outside of a Jupyter Notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `videos.stub` has a `LocalEntrypoint`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos.stub.registered_entrypoints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LocalEntrypoint`s let us define mixed local-remote executions\n",
    "like the one we just ran above and run them from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos.main\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```bash\n",
    "!modal run etl/videos.py --json-path data/mlops-world-videos.json\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ask-fsdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
